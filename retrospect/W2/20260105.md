# [2026.01.05] 일일 회고

## 1. 오늘의 한 줄 요약
> Actionable Data 개념을 접하며 어떤 Data Product를 만들어야 할 지 고민하게 되었음

---

## 2. 1일 리뷰

### (1) 수행 내역
- W1M3 리뷰를 통해 ETL 프로세스에서 어떤 부분들을 신경쓰며 구현해야 했는지 학습
- Parallelism에 대해 학습
- 멀티스레딩과 멀티프로세싱에 대해 학습하며, 어떤 상황에서 어떤 기술을 사용해야 하는지 학습
- W2M1, W2M2, W2M3 수행하며 python multiprocessing 모듈에 대해 학습
- W2 일정 관리 팀원들과 상의

### (2) 결과 / 산출물
- ETL 구현하며 conf의 별도 파일(yml)로의 분리, Region 데이터에 대한 출처 밝히기, Validation 처리 부족했음을 인지
- Parallel의 경우 시작/끝 모두 서로 communication 없이 독립적이어야 함
- W2M1, W2M2, W2M3 코드 작성 완료
- 1/6 오전까지 M4까지 개별 수행, 1/6 17시까지 M5 아이디어 초안 작성 후 팀원들과 공유
---

## 3. 회고 (KPT)

### (1) Keep
- M3 수행하며 일반적인 자료구조인 queue와 multiprocessing.Queue의 차이에 대해 고민하게 되었음. 비슷한 기능을 하지만 어떤 기능이 추가적으로 구현되었는지, 어떤 상황에 어떤 모듈이 필요한지 고민해보며 왜 추가적인 기능을 가진 자료구조가 필요하게 되었는지를 생각하자.

---

### (2) Problem
- 없음

---

### (3) Try
- 코드 작성할 때 validation 처리 염두에 두며, 어떤 예외, 에러 케이스가 생길지 고민하기 (함수 당 하나씩)

---

## 4. 오늘의 학습
### 4.1 수업
(1) W1M3 리뷰 – ETL 설계 관점
- ETL의 각 단계(E / T / L)는 서로 독립적인 시스템으로 구현되어야 함
- 시스템이 중간에 중단되더라도, 현재 데이터가 어떤 상태인지 어디까지 처리되었는지를 알 수 있어야 함
- 외부에서 수집한 데이터는 반드시 출처(Source)를 명시해야 함 → 수집 시점에 기록하지 않으면, 나중에 추적이 거의 불가능
- 설정값(conf)은 코드와 분리하여 yml 등 별도 설정 파일로 관리
- 특정 페이지 / 특정 데이터 소스를 가져오는 로직은 함수화 → 추후 수정 및 유지보수에 유리
- 데이터 Validation을 끝까지 처리하는 습관 필요
- Unit Test를 미리 작성해두는 것이 중요
- 기능, 요구사항을 빠르게 구현한 뒤 동료들과 코드 리뷰를 통해 개선하는 방식이 효율적

(2) 우리나라 데이터의 특징
- 제조 데이터 중심
- 독자적인 언어(한국어) 기반 데이터 → 글로벌 기업(예: Google)이 충분히 확보하지 못한 영역 → 네이버의 데이터 경쟁력으로 이어짐

(3) High-volume / High-velocity → 특정 시점에 데이터 양이 급격히 증가하는 특성 존재

(4) Parallelism & Data Processing
- Embarrassingly Parallel
- 시작과 끝에서조차 서로 communication 없이
- 각 작업이 완전히 독립적으로 수행되는 형태
- 이 구조에서 Data Parallelism이 매우 중요

(5) 멀티스레딩 vs 멀티프로세싱
1) 멀티스레딩이 적합한 경우
	- 네트워크 I/O, 디스크 I/O가 병목
	- CPU 사용 비중이 낮은 작업
	- AWS Lambda처럼 작은 메모리 / 작은 CPU 환경
	- 한 머신에서 무작정 스레드를 늘리기보다, 작은 컴퓨팅 리소스를 여러 개 사용하는 구조가 유리
2) 멀티프로세싱이 적합한 경우
	- CPU 코어와 메모리를 적극적으로 활용해야 하는 작업
3) Python의 GIL(Global Interpreter Lock)
	- 하나의 프로세스 내에서는 실질적으로 하나의 스레드만 CPU 실행
	- CPU-bound 작업은 멀티스레딩 효과가 제한적

(6) 분산 컴퓨팅 개념
- 분산 컴퓨팅 = 복수의 서버를 사용하는 구조
- 반드시 Data Parallelism이 전제되어야 함
- 각 서버는 메모리가 독립적이기 때문

(7) 시스템 안정성 개념
1) High Availability
	- 언제나 시스템이 동작하며 클라이언트 요청에 항상 응답을 주는 상태
2) Fault Tolerance
	- 시스템 관리자 관점에서의 장애 대응 능력
	- 장애 발생을 전제로 설계하는 개념

(8) Data Product & Actionable Data
- 데이터 프로덕트는 Actionable Data를 제공해야 함
- 단순한 인사이트 제공에서 끝나면 안 됨 → 그 자체로 행동(Action)을 유도할 수 있어야 함

(9) 문제 정의와 상품성 판단

	1.	문제 존재
	2.	당사자의 문제 인식
	3.	문제 해결을 위한 탐색 시작
	4.	(임시 해결책이 통하지 않거나, 돈이 부족한 상태)
		•	이 시점이 Sales가 가능한 타이밍
		•	대단히 큰 고통을 가진 사람을 찾고 → 그 사람이 실제로 돈을 지불할 의사가 있는지 판단하는 것이 데이터/제품의 상품성 판단 기준

### 4.2 미션 수행
(1) M1

- Python multiprocessing.Pool 핵심 정리
	- multiprocessing.Pool은 여러 개의 워커 프로세스를 미리 생성해 두고 작업을 분산 병렬 처리하기 위한 고수준 API
	- 스레드가 아닌 프로세스 기반 병렬 처리로, CPU-bound 작업에 적합
	- 프로세스 생성·종료를 자동으로 관리해줌

- Pool 주요 개념
	- processes: 워커 프로세스 개수 (기본값: CPU 코어 수)
	- initializer / initargs: 각 워커 시작 시 1회 실행되는 초기화 로직
	- maxtasksperchild: 워커당 처리 작업 수 제한 → 메모리 누수 방지

- 주요 메서드
	- map() : iterable을 병렬 처리, 결과 순서 보장, blocking
	- apply() : 단일 작업 동기 실행
	- apply_async() : 단일 작업 비동기 실행
	- imap() / imap_unordered() : iterator 형태 결과 반환 (unordered는 순서 미보장)
	- close() / terminate() / join() : 워커 종료 관리

- Context Manager 사용
	- with Pool(...) as pool: 형태 사용 시 close() + join() 자동 처리 → 자원 누수 방지

- if name == “main” 필요성
	- 새 프로세스가 파일을 다시 실행하므로 main 보호 없이 Pool 생성 시 무한 프로세스 생성 위험
	- 따라서 Pool 생성 코드는 반드시 main 블록 안에서 실행

(2) M2
- Python multiprocessing.Process 핵심 정리
	- multiprocessing.Process는 하나의 함수를 독립된 프로세스에서 실행하기 위해 직접 프로세스를 생성하는 클래스
	- 각 프로세스는 완전히 독립된 메모리 공간을 가짐
	- 프로세스의 실행 시점과 순서는 OS 스케줄러가 결정
	- 개발자가 start() / join()을 통해 프로세스 생명주기를 명시적으로 제어
- 실행 구조
	- 메인 프로세스: Process 생성 → start() → join()
	- 자식 프로세스: target 함수 실행
- 실행 순서가 매번 달라지는 이유
	- start()는 즉시 실행이 아니라 실행 가능 상태로 등록
	- 실제 실행 순서는 CPU 상태, 코어 수, 부하에 따라 OS가 결정
	- join()은 종료 대기만 보장, 실행 순서 보장 안함
	- 따라서 멀티프로세스에서는 출력 순서를 전제로 로직을 작성하면 안 됨
- Process vs Pool 차이
	- Process: 프로세스 생성·제어를 직접 관리하는 저수준 방식
	- Pool: 다수의 동일 작업을 자동 분산 처리하는 고수준 API
	- 목적에 따라 정밀 제어(Process) vs **대량 병렬 처리(Pool)**로 구분해 사용