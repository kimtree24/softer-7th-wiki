# [2026.01.13] 일일 회고

## 1. 오늘의 한 줄 요약
- 팀 아이디어 구체화 후 pros cons 작성 후 피드백 받을 아이디어 선정
- M1, M2a, M2b 완성

---

## 2. 1일 리뷰
- 하둡 시스템에 아직 익숙하지 않아서 인가, 여러 docker 컨테이너를 띄우고 이들간 관계를 생각하며 아키텍쳐 구현하는게 처음이라 그런가 과제에 어려움이 많았다.
우선은 구현은 완료했는데, 아직 어떤 설정값이 어디에 영향을 미치는 건지 온전히 파악하지 못해서 디버깅에 시간이 많이 걸리는 것 같다.
내일은 하나하나 어떤 설정값인지, 이 설정을 바꾸면 어디에 어떤 영향을 미치는지 따져봐야 할 것 같다.
docker images 빌드에 시간이 너무 오래 걸려서, 뭔가 캐시 지정을 해도 컨테이너 내리고, 지우고, 리빌드 하고 이런 과정들이 귀찮아서 어떻게 하면 조금 빠르고 편하게 할 수 있을지 고민이 된다.

-미션이 어려워서 시간에 쫒기는 것 같다. 시간에 쫒기면 구현에 급급해지는데, 마감일 지키는 것과 퀄리티 사이에서의 갈등은 항상 되는 것 같다.

- 팀 아이디어 회의를 하며 결국 다시 처음부터 아이디어를 내야 하는 원점으로 돌아갔다. 우선은 많은 피드백을 받아보고자 세개의 의견 중 가장 문제정의가 잘 되었다고 생각한 아이디어를 선정했다. 해당 아이디어는 데이터 엔지니어링 적으로 풀 수 있는 문제인가? 에 대해서는 의문이 남지만, 문제 정의 자체만 보면 가장 고통이 있고, 수요도 있을 것 같아 어떤 피드백이 올 지 궁금하다.

---

## 3. 회고 (KPT)

### (1) Keep
- 미션 수행하며 방향성이 헷갈릴 때 이 미션을 왜 해야하는지에 대한 고민을 하며 미션 방향을 잡았다. 옳은 답인지는 아직 모르겠으나, 왜 이 작업을 해야 하는지에 대한 고민을 하며 나아가는 건 좋았다.

---

### (2) Problem
- 팀 회의 타임박싱 함에도 불구하고 계속 5분 10분씩 타임오버가 된다. -> 타임오버는 3분까지만 허용하자 -> 이후에는 그냥 끊자.

---

### (3) Try
- 하둡 아키텍처 공부하기 -> 공부 방향을 어떻게 잡으면 좋을까... -> 이번주는 매일 아침 하둡 아키텍처 그려보기(익숙해지자)

---

## 4. 오늘의 학습
### (1) Docker에서 FROM ubuntu는 OS인가
- Docker 이미지는 커널을 포함하지 않음.
- FROM ubuntu:22.04는 부팅 가능한 OS가 아니라 **Ubuntu 사용자 공간(rootfs)**

```
Docker Image = root filesystem + 라이브러리 + 쉘 + 패키지
```

커널은 **호스트의 리눅스 커널을 공유**
그래서
- systemd 없음
- 부팅 없음
- PID 1 = CMD로 실행한 프로세스

---

### (2) eclipse-temurin vs ubuntu
FROM eclipse-temurin:8-jdk는 Java가 포함된 **최소 리눅스 환경** 
Hadoop은 Java만 필요하므로 ubuntu보다 가벼운 eclipse-temurin 선택

---

### (3) JAVA_HOME 에러의 정체
Hadoop은 내부 스크립트에서 다음을 실행함.
```
$JAVA_HOME/bin/java
```
eclipse-temurin에서는:
```
JAVA_HOME=/opt/java/openjdk
```
이를 반드시 hadoop-env.sh에 설정해야 함

---

### (4) root로 실행 시 HDFS 오류
Hadoop은 원래 `hdfs`, `yarn`, `mapred` 유저로 실행되도록 설계됨.  
Docker에서는 root로 실행되므로 아래 우회가 필요

```
HDFS_NAMENODE_USER=root
HDFS_DATANODE_USER=root
YARN_RESOURCEMANAGER_USER=root
YARN_NODEMANAGER_USER=root
```

---

### (5) Master / Worker 역할 분리
| 역할 | 서비스 |
|---|---|
| Master | NameNode, ResourceManager |
| Worker | DataNode, NodeManager |

이미지 구조:
```
hadoop-base
  ├─ hadoop-master
  └─ hadoop-worker
```
컨테이너:
```
namenode(master), worker1, worker2
```

---

### (6) 같은 Docker 네트워크의 의미
Hadoop은 hostname으로 통신
```
worker1 → namenode:9000
worker2 → namenode:8032
```
따라서 docker-compose에서 **같은 네트워크**가 필수

---

### (7) hostname = Hadoop host
`fs.defaultFS = hdfs://namenode:9000` 이라면  
docker-compose의 hostname도 `namenode`여야 합니다.

---

### (8) DataNode hostname 설정
Docker IP는 재시작 시 바뀜 
따라서 HDFS는 hostname을 사용해야 함

```xml
dfs.datanode.use.datanode.hostname=true
dfs.client.use.datanode.hostname=true
```

---

### (9) SafeMode
NameNode는 부팅 후 블록 확인 전까지 쓰기 금지(SafeMode)입니다.
필요 시:
```
hdfs dfsadmin -safemode leave
```

---

### (10) mapreduce_shuffle 오류
YARN에서 MapReduce Shuffle 서비스 등록 필요:

```xml
yarn.nodemanager.aux-services=mapreduce_shuffle
yarn.nodemanager.aux-services.mapreduce.shuffle.class=org.apache.hadoop.mapred.ShuffleHandler
```

---

### (11) getconf vs 실제 HDFS
- `getconf` → 설정 파일만 확인
- `hdfs dfs` → NameNode에 실제 연결  
네트워크가 깨지면 getconf는 PASS, hdfs는 FAIL 가능

---

### (12) M2a vs M2b
| M2a | M2b |
|---|---|
| 설정을 이미지에 bake | 설정을 볼륨으로 마운트 |
| docker build 필요 | XML 수정 후 재시작 |
| 개발자 관점 | 운영자 관점 |
