# [2026.01.15] 일일 회고

## 1. 오늘의 한 줄 요약
- 이번주차 미션 다시 복기하며 부족했던 부분 학습

---

## 2. 1일 리뷰
- M6관련해서 데이터셋이 워낙 크다 보니 이런저런 트러블 슈팅 할 부분이 많았다. config 설정을 바꾸지 않고, 기본 값으로 두니 메모리 문제로 하둡 시스템이 아예 죽어버리는 경우가 있었다.
- 이번주차 수행한 미션들을 다시 검토하고, 코드 분석하며 README를 적는 과정들이 꽤 시간이 걸린 것 같다. 그래도 일주일치 미션을 모두 수행하고 다시 첫 미션부터 다시 검토하니, 조금 더 이해가 잘 되는 느낌이었다.

- 팀 아이디어 관련해서 어떻게 문제를 해결할 것인지, 빅데이터를 활용할 수 있는지에 대한 고민은 차치하고 그냥 문제에만 집중해서 생각하니 조금 더 구체화된 문제 정의가 되는 느낌이 있다. 다만 100만원을 지불할 딱 한명을 타겟팅 하다 보니 그 사람, 그 입장이 아니면 다른 사람은 이 문제를 진짜 문제라고 인식하나? 라는 의문이 든다.

---

## 3. 회고 (KPT)

### (1) Keep
- 일주일 미션 모두 끝내고 다시 처음부터 복습한 부분이 좋았다. 초반에 진행한 미션들에 대해 이해하지 못하고 넘어갔던 부분, 부족한 부분등이 느껴졌다. 다음주도 목/금에는 일주일 미션을 다시 복습하는 시간 가지자

---

### (2) Problem
- 19시까지 무조건 회고 작성하고 운동가야 하는데 늦어졌다. 팀 회의가 조금 길어져 전체적으로 딜레이 되었는데 타임 박싱 맨날 problem에 적는데 잘 안지켜진다. -> 조금 더 타임 박싱 촘촘히 하자

---

### (3) Try
- 없음

---

## 4. 오늘의 학습

# Hadoop MapReduce WordCount

## 1. 개념 정리

### 1.1 Hadoop Streaming
Mapper와 Reducer는 표준입출력(STDIN/STDOUT) 기반으로 동작한다. Python 스크립트에서 `print`는 곧 Hadoop으로 보내는 (key, value) 출력이며, return 값은 무시된다.

### 1.2 Docker Volume과 HDFS의 역할 분리
- ebook.txt: Docker volume으로 master 컨테이너에 주입
- HDFS: DataNode에 분산 저장
데이터와 HDFS 메타데이터를 분리 마운트해야 안정적이다.

### 1.3 NameNode, DataNode, YARN
- NameNode: 메타데이터 관리
- DataNode: 실제 블록 저장
- YARN: MapReduce 작업을 각 DataNode로 스케줄링

## 2. 아키텍처 및 네이밍 이슈

### 2.1 hostname vs container_name
Hadoop은 Docker의 container_name이 아니라 컨테이너 hostname과 core-site.xml의 fs.defaultFS를 기준으로 NameNode를 찾는다. 따라서 hostname과 fs.defaultFS는 반드시 일치해야 한다.

### 2.2 workers 파일
workers 파일에 정의된 호스트명과 Docker Compose의 hostname이 일치해야 DataNode가 정상 등록된다.
